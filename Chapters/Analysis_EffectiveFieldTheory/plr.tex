\section{Statistical Method}

\par
In direct dark matter searches, hypothesis testing is frequently used to determine whether an observation excludes a dark matter model or is significant enough to claim a discovery.
This is often performed using a frequentist approach where there are two well defined hypotheses, a null hypothesis ($H_0$) and an alternative hypothesis ($H_1$), which are tested to see which is the most compatible with the observation \cite{likelihood_testing_ref}.
In general the null hypothesis is assumed to be true and is either rejected in favour of the alternative or is failed to be rejected, neither hypothesis is ever accepted.
Each hypothesis represent models that could describe the observation.
The parameter of interest (POI), $\mu$, in $H_0$ is fixed to a defined value and is set to float in $H_1$ to all other possible values:
\begin{equation}
    \begin{split}
        H_0: \mu = \mu_0 \\
        H_1: \mu \neq \mu_0
    \end{split}
\end{equation}
In the analyses in this chapter, $\mu$ is just the number of WIMP-nucleon scatters that are expected in each model, and $\mu_0$ is the expected number of WIMP-nucleon scatters in the dataset.

\par
In the limit setting analyses in this chapter, $H_0$ is defined as the background plus signal model and $H_1$ as the background only model.
By testing a signal model with a range of POI\footnote{varying the number of signal events expected}, a p-value cal be calculated. 
Upper limits are set when the POI is disfavoured if a predicted signal rate is significantly different to the observed rate.
The test statistic used to assess the POI is defined by a negative log-likelihood:
\begin{equation}
    q = -2 \text{ln}(\lambda)
\end{equation}
where $\lambda$ is the actual PLR defined as:
%$\lambda$ is comprised of the profile likelihood give by
\begin{equation}
    \lambda(\mu) = \frac{\mathcal{L}(\mu_0, \boldsymbol{\hat{\hat{\nu}}})}{\mathcal{L}(\hat{\mu}, \boldsymbol{\hat{\nu}})}
\end{equation}
$\boldsymbol{\nu}$ are a set of nuisance parameters in each model which are the level of each background.
The parameters with hats are allowed to float to maximise the likelihood.
The difference between the single and double hat nuisance parameters is to take into account that the values of the nuisance parameters which maximise the likelihood when $\mu$ is fixed are not the same as those which maximise the likelihood when $\mu$ can float.
\par
An unbinned likelihood has been used in the analyses in this chapter, which contains both signal and background components, defined as:
\begin{equation}
\begin{split}
    \mathcal{L}(\mu_s,\boldsymbol{\nu}) =& \text{Pois} \bigg(N_0 | \mu_s + \sum^{N_b}_{b=1} \mu_b \bigg) \\
                                         & \times \prod^{N_0}_{e=1} \frac{1}{\mu_s + \sum^{N_b}_{b=1} \mu_b} \bigg( \mu_s f_s (\boldsymbol{x}_e) + \sum^{N_b}_{b=1} \mu_b f_b(\boldsymbol{x}_e) \bigg) \\
                                         & \times \prod^{N_b}_{b=1} f_b(\mu_b | a_b)
\end{split}
\end{equation}
In the above equation, $N_b$ is the total number of background components considered in the analysis, and $\mu_s$ and $\mu_b$ are the levels of the signal and background, respectively. 
$f_s(\boldsymbol{x}_e)$ and $f_b(\boldsymbol{x}_e)$ are functions of the observable parameters,  $\boldsymbol{x}_e$, which describing the components signal and background components.
$f_b(\mu_b | a_b)$ are constraint functions on the rate of each background.
Generally, these are Gaussian distributions, the width of which is defined by the uncertainty of the backgrounds.
$e$ represents running over each event in the data set of size $N_0$.

\par
For both analyses, only two observables are considered \{$S1_c,\text{log}_{10}(S2_c)$\}.
As such the signal and background PDFs are 2-dimensional, constructed from \{$S1_c,\text{log}_{10}(S2_c)$\} only.
The codebase used which runs the PLR, \textit{LZStats}, was developed primarily by I. Olicina using \textit{RooStats} \cite{roostats_ref}.
Details of the code can be found in his thesis \cite{LZ_Ibles_LZStats_Thesis_ref}.


\iffalse
The outcome of the test is then either there not being enough evidence to reject a background only described what was observed or that the background model is rejected in favour of a background plus signal model.
There models are comprised of the expected number of event for the background (or background plus signal) and a PDF which 


\par
In the projected study the test is summarised as:
"finding the value $\mu$ above which the background plus signal model is incompatible with a background only model.

Which has a dependency on the PDFs of both signal and backgrounds, $f_s($\textbf{$x_e$}) and $f_b($\textbf{$x_e$}).

For considering $N$ backgrounds in the model.
The log-likelihood for the analysis is given by:



\subsection{Model PDFs}
\par
In both the projected sensitivity study and the SR1 study the PDFs were created in the same fashion, albeit with different software package\footnote{The tool for generating the PDFs used in the collaboration changed between when these two studies were done}.



The approaches fall into two categories: those simulated through \textit{BACCARAT}, and those  simulated through the full-chain and not.

\par
Backgrounds which are unique to LZ as they are from the local environment were all simulated in \textit{BACCARAT} as energy deposit simulations.
In the case of the projected limits, analysis cuts were applied at this stage, so are on the simulation truth as a detector response for 
The energy deposits were when fed into a detector


\par

Contributions from neutrions were determined via DMCalc. 



The simulations used to produce the PDFs for the PLR originate from those used in \cite{LZ_projected_sensitivity_paper_ref} where an energy deposit only approach was adopted based upon a detector response model for which the author takes no credit and so only the essential information is detailed here.
A more complete description of the simulation framework and detector response can be found in the following Refs. \cite{lz_simulations_ref,theresafruth_thesis_ref}.
\par
In order to determine the detector response, a set of simulations were performed in the standard fashion; where an energy deposit in xenon is translated into scintillation photons and ionisation electrons using NEST \cite{nest_1_ref,nest_2_ref}.
These were then propagated until eventual detection (or not) at the PMT faces where the PMT response is then incorporated.
The resultant sum of these responses give us the S1 and S2 pulse sizes from which the detector response is made from, describing the size of the S1 and S2 for a given recoil.
Our detector is then described by a finite number of parameters given \autoref{tab:projected_sensitivity_detector_parameters} and the response in S1$_c$ and S2$_c$ for a NR events is shown in \autoref{fig:projected_detector_model_response_for_flat_nr}.
When it comes time to generate the PDFs required for our PLR we can simply use the differential scattering rate per recoil energy.


\begin{equation}
\begin{split}
    \mathcal{L}(\mu_s,\boldsymbol{\nu}) =& \text{Pois}(N | \mu_{tot}) \\
                                     &\times \prod^{n_0}_{e=1} \frac{1}{\mu_{tot}} \bigg(\mu_s f_s(\boldsymbol{x}_e)  + \sum^N_{b=1} \mu_b f_b(\boldsymbol{x}_e) \bigg) \\
                                     &\times \prod^{N}_{b=1} f_b (\mu_b | \nu_b )
\end{split}
\end{equation}
where $\mu_{tot}$ is the total background 


\begin{equation}
\begin{split}
    -2 \text{log}\mathcal{L}(\mu_s(\sigma),\textbf{\nu}) =& 2\bigg(\mu_s + \sum^{N}_{b=1} \mu_b \bigg) \\
                                                          &-2\sum^{n_0}_{e=1} \bigg(\text{log}(\mu_s f_s(x_e)  + \sum^N_{b=1}\mu_b f_b(x_e)
                                                          \bigg) \\
                                                          &+\sum^N_{b=1} \frac{(\mu_b - a_b)^2}{s^2_b}
\end{split}
\end{equation}

\fi
